# Implementation Plan: Comprehensive Unit Test Suite for Circuit Algorithms

**Branch**: `003-unit-test-suite` | **Date**: 2025-12-12 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/003-unit-test-suite/spec.md`

**Note**: This plan was generated by the `/speckit.plan` command.

## Summary

Create a comprehensive unit test suite for all core algorithm components to address a critical bug where a 4-capacitor classroom example with a known exact solution returns 7.69% error instead of finding the exact configuration. The test suite will validate mathematical correctness, enable regression testing, and support test-driven refactoring of algorithm code to be more modular and testable. Minimum 20 comprehensive test cases covering series-parallel enumeration, graph topology generation, capacitance calculations, and heuristic search algorithms.

## Technical Context

**Language/Version**: Python 3.7.4+ (existing codebase)  
**Primary Dependencies**: pytest ≥5.0 (existing), NumPy ≥1.24, NetworkX ≥3.1  
**Storage**: N/A (algorithmic testing)  
**Testing**: pytest with markers (unit, integration, contract) - existing infrastructure  
**Target Platform**: Cross-platform (Windows/Linux/macOS development environments)  
**Project Type**: Single project - Python package with core algorithms and UI separation  
**Performance Goals**: Test suite execution < 30 seconds total (unit tests < 10s, regression tests < 20s)  
**Constraints**: Cannot break existing UI dependencies; floating-point comparisons require epsilon tolerance (1e-10 for exact solutions); deterministic test execution required  
**Scale/Scope**: 20+ comprehensive test cases; 100% coverage of core algorithm functions (sp_enumeration.py, graphs.py, heuristics.py, sp_structures.py, parsing.py, metrics.py)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### I. Modular Architecture ✅ COMPLIANT

**Requirements**: Core modules (`capassigner/core/`) MUST have no Streamlit dependencies; pure Python algorithms only

**Status**: ✅ This feature enhances testability of existing core modules without introducing UI dependencies. Tests will verify algorithms in isolation, reinforcing modular architecture.

**Verification**: All new tests are in `tests/` directory, no Streamlit imports in test files for core algorithms.

---

### IV. Algorithmic Correctness ✅ COMPLIANT

**Requirements**: All capacitance calculations MUST be mathematically correct (series formula, parallel formula, Laplacian method)

**Status**: ✅ This feature directly addresses algorithmic correctness by:
- Validating that series formula 1/C_eq = Σ(1/Ci) is correct (FR-005)
- Validating that parallel formula C_eq = ΣCi is correct (FR-006)
- Testing Laplacian method for graph topologies (FR-007)
- Ensuring exact solutions are found when they mathematically exist (FR-002)

**Verification**: Test cases will include hand-calculated expected results for known configurations, validated against mathematical formulas.

---

### V. Deterministic Reproducibility ✅ COMPLIANT

**Requirements**: Heuristic searches MUST be reproducible (same seed + same parameters → identical results)

**Status**: ✅ FR-010 requires tests to use deterministic inputs with fixed random seeds for reproducibility.

**Verification**: Random algorithm tests will use explicit seed parameters in test cases.

---

### Quality & Testing: Test Coverage ✅ ENHANCED

**Requirements**: Test structure with unit/, integration/, contract/ directories; pytest configuration

**Status**: ✅ This feature significantly enhances existing test infrastructure:
- Comprehensive unit tests for all core algorithm components (FR-003)
- Regression tests for known configurations (FR-004)
- 20+ test cases minimum (clarification)
- Target 100% core algorithm coverage (SC-004)

**Verification**: pytest coverage tools will measure and report coverage metrics.

---

**GATE STATUS**: ✅ **PASSED** - All constitutional principles are upheld. No violations or complexity increases.

## Project Structure

### Documentation (this feature)

```text
specs/003-unit-test-suite/
├── spec.md              # Feature specification (completed)
├── plan.md              # This file (current)
├── research.md          # Phase 0 output (to be generated)
├── data-model.md        # Phase 1 output (to be generated)
├── quickstart.md        # Phase 1 output (to be generated)
├── contracts/           # Phase 1 output directory (to be generated)
│   └── test-*.yaml      # Test case contract definitions
├── checklists/          # Quality validation
│   └── requirements.md  # Specification checklist (completed)
└── tasks.md             # Phase 2 output (generated by /speckit.tasks - NOT by this command)
```

### Source Code (repository root)

```text
capassigner/
├── __init__.py
├── config.py              # Constants (existing)
├── core/                  # Pure Python algorithms (NO CHANGES - test targets)
│   ├── __init__.py
│   ├── graphs.py          # Graph topology and Laplacian analysis
│   ├── heuristics.py      # Random graph heuristic search
│   ├── metrics.py         # Error calculations and solution ranking
│   ├── parsing.py         # Capacitance value parsing
│   ├── sp_enumeration.py  # SP topology enumeration with memoization
│   └── sp_structures.py   # Series-parallel tree dataclasses
└── ui/                    # Streamlit UI (MAY NEED UPDATES if API changes)
    ├── __init__.py
    ├── pages.py
    ├── plots.py
    ├── theory.py
    └── tooltips.py

tests/                     # TEST SUITE (PRIMARY WORK AREA)
├── __init__.py
├── conftest.py            # pytest fixtures (TO BE ENHANCED)
├── contract/              # API contract tests (NEW TESTS)
│   ├── __init__.py
│   └── test_algorithm_contracts.py  # NEW: API stability tests
├── integration/           # Integration tests (NEW TESTS)
│   ├── __init__.py
│   ├── test_workflows.py  # EXISTING: may be enhanced
│   └── test_end_to_end.py # NEW: Full workflow validation
└── unit/                  # Unit tests (ENHANCED)
    ├── __init__.py
    ├── test_graphs.py         # EXISTING: will be enhanced
    ├── test_heuristics.py     # EXISTING: will be enhanced
    ├── test_metrics.py        # EXISTING: will be enhanced
    ├── test_parsing.py        # EXISTING: will be enhanced
    ├── test_sp_enumeration.py # EXISTING: will be enhanced
    ├── test_sp_structures.py  # EXISTING: will be enhanced
    ├── test_regression.py     # NEW: Regression test suite with 20+ cases
    └── test_fixtures.py       # NEW: Shared test data and fixtures
```

**Structure Decision**: Leveraging existing single-project layout with core/ui separation. Primary work in `tests/` directory to enhance existing test infrastructure. **Note**: Core algorithm module internal APIs may change per FR-009 (breaking changes acceptable for testability; UI layer will be updated accordingly).

## Complexity Tracking

*No constitutional violations - this section is empty.*

All test enhancements strengthen existing constitutional principles (Modular Architecture, Algorithmic Correctness, Deterministic Reproducibility). No new complexity introduced.

---

## Phase 0: Research & Best Practices

**Status**: ✅ **COMPLETE** - See [research.md](./research.md)

**Key Decisions**:
1. ✅ Systematic component testing approach for isolating 4-capacitor bug
2. ✅ Tiered tolerance strategy: 1e-10 (exact), 1e-6 (approximate), variable (user)
3. ✅ pytest fixtures with conftest.py + dedicated fixture module pattern
4. ✅ Parameterized regression tests for 20+ cases without duplication
5. ✅ Dependency injection refactoring: pure functions with explicit parameters
6. ✅ Multi-layer performance optimization: markers, small inputs, parallel execution
7. ✅ Self-documenting test structure with clear naming and docstrings
8. ✅ Explicit exception testing for edge cases with pytest.raises

**Deliverables**:
- ✅ [research.md](./research.md) - Comprehensive best practices with rationale
- ✅ Resolved all NEEDS CLARIFICATION items (none were present)
- ✅ Documented approach for fixing 4-capacitor bug
- ✅ Established testing patterns and conventions

---

## Phase 1: Design & Contracts

**Status**: ✅ **COMPLETE** - See artifacts below

**Deliverables**:
- ✅ [data-model.md](./data-model.md) - Test case entities and structure
  - Defined TestCase, RegressionSuite, AlgorithmComponent entities
  - Defined ToleranceLevel, TestFixture, AssertionHelper utilities
  - Defined TestMetrics for monitoring test suite health
  - Included 20+ test case categorization breakdown

- ✅ [contracts/test-contracts.yaml](./contracts/test-contracts.yaml) - Test case schemas
  - TestCase contract with validation rules
  - RegressionSuite contract with 20+ minimum cases
  - ToleranceLevel contract with predefined levels
  - AlgorithmComponent contract for core modules
  - TestMetrics contract with thresholds

- ✅ [quickstart.md](./quickstart.md) - Developer guide
  - Quick reference for running tests
  - Test fixture usage examples
  - Assertion helper patterns
  - Debugging and coverage instructions
  - Integration with TDD workflow

- ✅ Agent Context Update
  - Updated `.github/agents/copilot-instructions.md` with testing context
  - Added pytest, coverage, and test fixture technologies

---

## Phase 1.5: Constitution Re-Check

**Status**: ✅ **PASSED** - All principles upheld, no new violations

### I. Modular Architecture ✅ CONFIRMED

Post-design verification: Test suite maintains strict separation between core algorithm testing and UI. All new test files are in `tests/` directory with no Streamlit imports for core algorithm tests.

### IV. Algorithmic Correctness ✅ CONFIRMED

Post-design verification: Data model and contracts explicitly define validation of mathematical formulas:
- Series formula: 1/C_eq = Σ(1/Ci)
- Parallel formula: C_eq = ΣCi
- Laplacian method for graph topologies
- 1e-10 tolerance for exact solutions ensures mathematical precision

### V. Deterministic Reproducibility ✅ CONFIRMED

Post-design verification: Research document establishes pattern for deterministic testing with fixed seeds. AlgorithmComponent contract requires `deterministic: true` flag and seed parameters for randomized algorithms.

**Final Gate Status**: ✅ **APPROVED FOR IMPLEMENTATION**

---

## Implementation Notes

### Execution Order

**Phase 2 (Tasks Generation)**: Run `/speckit.tasks` to generate detailed task breakdown

**Phase 3+ (Implementation)**: Follow task order:
1. **P1 - Critical Bug Fix**: Start with 4-capacitor classroom example test
2. **P2 - Regression Suite**: Build 20+ test case library
3. **P3 - Component Testing**: Unit tests for each algorithm module
4. **P4 - Refactoring**: Make algorithms more testable if needed

### Key Implementation Considerations

1. **Bug Investigation First**:
   - Create failing test for 4-capacitor classroom example
   - Debug why expected topology not found or has 7.69% error
   - Fix root cause in algorithm (likely SP enumeration or C_eq calculation)
   - Verify test passes with < 1% error (ideally 0%)

2. **Test Data Collection**:
   - Need actual values from bug report PDF for classroom example
   - Hand-calculate expected C_eq for test validation
   - Identify expected topology structure
   - Document source and calculation method

3. **Refactoring Strategy** (if needed):
   - Breaking changes to internal APIs are acceptable (FR-009 clarification)
   - Update UI imports/calls in same feature branch
   - Prioritize testability over backward compatibility
   - Use dependency injection for random number generators

4. **Performance Monitoring**:
   - Use `pytest --durations=10` to identify slow tests
   - Consider `pytest-xdist` for parallel execution if needed
   - Keep individual test cases under 2 seconds where possible
   - Reserve N≥7 cases for explicit slow test markers

5. **Coverage Targets**:
   - Use `pytest-cov` to measure coverage
   - Target 100% for core algorithm functions (FR-003, SC-004)
   - Focus on branch coverage, not just line coverage
   - Document any intentionally uncovered code (e.g., error handling for impossible cases)

---

## Success Metrics

From spec Success Criteria, measurable at implementation completion:

- ✅ **SC-001**: 4-capacitor classroom example error < 1% (improvement from 7.69%)
- ✅ **SC-002**: Algorithm finds exact solutions (relative error < 1e-10) for all known exact cases
- ✅ **SC-003**: Test suite execution < 30s total (unit < 10s, regression < 20s)
- ✅ **SC-004**: 100% coverage of core algorithm functions
- ✅ **SC-005**: 0 regressions after refactoring (all existing tests pass)
- ✅ **SC-006**: Test failures identify specific algorithm component and step
- ✅ **SC-007**: Algorithm accuracy > 95% for valid problem instances
- ✅ **SC-008**: Test suite runs without UI dependencies

---

**Ready for Phase 2**: Run `/speckit.tasks` to generate implementation tasks

| Violation | Why Needed | Simpler Alternative Rejected Because |
|-----------|------------|-------------------------------------|
| [e.g., 4th project] | [current need] | [why 3 projects insufficient] |
| [e.g., Repository pattern] | [specific problem] | [why direct DB access insufficient] |
